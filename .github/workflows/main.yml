name: Ollama + Web Stack via Tailscale

on:
  workflow_dispatch:

jobs:
  server:
    runs-on: ubuntu-latest
    timeout-minutes: 620

    steps:
      # ---------------------------
      # System Info
      # ---------------------------
      - name: Show System Info
        run: |
          echo "CPU:"
          lscpu | grep "Model name"
          echo "RAM:"
          free -h
          echo "Disk:"
          df -h

      # ---------------------------
      # Install Base Packages
      # ---------------------------
      - name: Install Base Packages
        run: |
          sudo apt update
          sudo apt install -y curl wget git gnupg2 ca-certificates \
            lsb-release software-properties-common apt-transport-https

      # ---------------------------
      # Install Node.js 22
      # ---------------------------
      - name: Install Node.js
        run: |
          curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -
          sudo apt install -y nodejs
          node -v
          npm -v

      # ---------------------------
      # Install PM2
      # ---------------------------
      - name: Install PM2
        run: |
          sudo npm install -g pm2
          pm2 -v

      # ---------------------------
      # Install Nginx
      # ---------------------------
      - name: Install Nginx
        run: |
          sudo apt install -y nginx
          sudo systemctl start nginx || true
          curl -I http://localhost

      # ---------------------------
      # Install Tailscale
      # ---------------------------
      - name: Install Tailscale
        run: curl -fsSL https://tailscale.com/install.sh | sh

      - name: Start Tailscale
        run: |
          sudo tailscale up \
            --authkey=${{ secrets.TAILSCALE_AUTHKEY }} \
            --accept-dns=true

      - name: Get Tailscale IP
        id: tsip
        run: |
          IP=$(tailscale ip -4)
          echo "ip=$IP" >> $GITHUB_OUTPUT
          echo "Tailscale IP: $IP"

      # ---------------------------
      # Install Webmin (Direct .deb)
      # ---------------------------
      - name: Install Webmin
        run: |
          sudo apt install -y perl libnet-ssleay-perl openssl \
            libauthen-pam-perl libpam-runtime libio-pty-perl \
            apt-show-versions python3

          wget https://www.webmin.com/download/deb/webmin-current.deb
          sudo dpkg -i webmin-current.deb || sudo apt -f install -y
          sudo /etc/webmin/start

          sudo /usr/share/webmin/changepass.pl /etc/webmin \
            ${{ secrets.WEBMIN_USER }} \
            ${{ secrets.WEBMIN_PASS }}

          echo "Webmin user created"

      # ---------------------------
      # Install Ollama
      # ---------------------------
      - name: Install Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          sleep 5
      
      # ---------------------------
      # Wait for Ollama API
      # ---------------------------
      - name: Wait for Ollama
        run: |
          for i in {1..40}; do
            if curl -s http://localhost:11434/api/tags > /dev/null; then
              echo "Ollama ready"
              break
            fi
            sleep 3
          done
      
      # ---------------------------
      # Pull Base Model
      # ---------------------------
      - name: Pull qwen2.5-coder:14b
        run: ollama pull qwen2.5-coder:14b
      
      # ---------------------------
      # Create 16K Context Model
      # ---------------------------
      - name: Create 16K Context Model
        run: |
          cat <<EOF > Modelfile
          FROM qwen2.5-coder:14b
          PARAMETER num_ctx 16384
          PARAMETER num_predict 512
          PARAMETER temperature 0.2
          EOF
      
          ollama create qwen14b-16k -f Modelfile
      
      # ---------------------------
      # Run Model (Test Prompt)
      # ---------------------------
      - name: Test Run
        run: |
          ollama run qwen14b-16k "Write a Python function for binary search"




      

      # ---------------------------
      # Clone Your Next.js Repo
      # ---------------------------
      - name: Deploy Next.js App
        run: |
          sudo mkdir -p /var/www
          sudo chown $USER:$USER /var/www
          cd /var/www
          git clone https://github.com/madmadhu-1002/ollama-gpt.git
          cd ollama-gpt
          npm install
          npm run build

      # ---------------------------
      # Start Next.js with PM2
      # ---------------------------
      - name: Start Next.js App
        run: |
          cd /var/www/ollama-gpt
          pm2 start npm --name ollama-gpt -- start
          pm2 status

      # ---------------------------
      # Show Access Info
      # ---------------------------
      - name: Show Access Info
        run: |
          echo "========================================"
          echo "Tailscale IP: ${{ steps.tsip.outputs.ip }}"
          echo ""
          echo "Next.js:"
          echo "http://${{ steps.tsip.outputs.ip }}:3000"
          echo ""
          echo "Ollama API:"
          echo "http://${{ steps.tsip.outputs.ip }}:11434"
          echo ""
          echo "Webmin:"
          echo "https://${{ steps.tsip.outputs.ip }}:10000"
          echo ""
          echo "Model: qwen2.5-coder:7b"
          echo "========================================"

      # ---------------------------
      # Keep Runner Alive
      # ---------------------------
      - name: Keep Runner Alive
        run: sleep 6h
